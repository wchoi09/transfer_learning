{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine_tuning_train_custom.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGWVzanEeMw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFc3hk-0ecZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Conv2D\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Nadam, Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7zCGr9Fesjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "sess_config = ConfigProto()\n",
        "sess_config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
        "sess_config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=sess_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSgsQcVeK_rC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HzhrQm3K8U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_PATH = \"dataset\"\n",
        "WARMUP_PLOT_PATH = os.path.sep.join([\"output\", \"warmup.png\"])\n",
        "\n",
        "# VALUE INIT\n",
        "IMG_SIZE = 224\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "base_learning_rate = 2e-4\n",
        "BATCH_SIZE = 32\n",
        "initial_epochs = 30\n",
        "fine_tune_epochs = 10\n",
        "#total_epochs = initial_epochs - fine_tune_epochs\n",
        "total_epochs = fine_tune_epochs\n",
        "\n",
        "# initialize the list of class label names\n",
        "CLASSES = [\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\", \"Meat\", \"Noodles/Pasta\", \"Rice\", \"Seafood\", \"Soup\", \"Vegetable/Fruit\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwbIh6Kle98O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_training(history, N, plotPath):\n",
        "    # construct a plot that plots and saves the training history\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZw4TpLse9-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# derive the paths to the training, validation, and testing\n",
        "# directories\n",
        "trainPath = os.path.sep.join([BASE_PATH, \"training\"])\n",
        "valPath = os.path.sep.join([BASE_PATH, \"validation\"])\n",
        "testPath = os.path.sep.join([BASE_PATH, \"evaluation\"])\n",
        "\n",
        "# determine the total number of image paths in training, validation, \n",
        "# and testing directories\n",
        "totalTrain = len(list(paths.list_images(trainPath)))\n",
        "totalVal = len(list(paths.list_images(valPath)))\n",
        "totalTest = len(list(paths.list_images(testPath)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHxsZ4Y4e-BS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the training data augmentation object\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "train_datagen.mean = mean\n",
        "val_datagen.mean = mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKGkxktHe-Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the training generator\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "    trainPath,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "# initialize the validation generator\n",
        "validation_batches = val_datagen.flow_from_directory(\n",
        "    valPath,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "# initialize the testing generator\n",
        "test_batches = val_datagen.flow_from_directory(\n",
        "    testPath,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zniCppke-G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the base model from the pre-trained model \n",
        "#base_model = VGG16(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False)\n",
        "base_model = MobileNetV2(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False, layers=tf.keras.layers) # added layers=tf.keras.layers for batch normalization problem: still not working\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "# let's add a fully-connected layer\n",
        "#x = Dense(512, activation=\"relu\")(x) # VGG16\n",
        "x = Dense(128, activation=\"relu\")(x) # mobilenetv2\n",
        "x = Dropout(0.5)(x)\n",
        "# and a logistic layer -- let's say we have config2.CLASSES classes\n",
        "predictions = Dense(len(CLASSES), activation=\"softmax\")(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbClhdK4e-O5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    #if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "    if isinstance(layer, tf.python.keras.layers.normalization_v2.BatchNormalization):\n",
        "        layer._per_input_updates = {}\n",
        "\n",
        "# loop over the layers in the model and show which ones are trainable\n",
        "# or not\n",
        "for layer in base_model.layers:\n",
        "    print(\"{}: {}\".format(layer, layer.trainable))\n",
        "\n",
        "print('This is the number of trainable weights '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1L45m0We-M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "#opt = SGD(lr=base_learning_rate, momentum=0.9, decay=0.01)\n",
        "opt = SGD(lr=base_learning_rate, momentum=0.9, decay=base_learning_rate/initial_epochs)\n",
        "#opt = Adam(lr=base_learning_rate, decay=base_learning_rate/initial_epochs)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network for a few epochs (all other layers\n",
        "# are frozen) -- this will allow the new FC layers to start to become\n",
        "# initialized with actual \"learned\" values versus pure random\n",
        "print(\"[INFO] training head...\")\n",
        "history = model.fit(train_batches,\n",
        "    epochs=initial_epochs,\n",
        "    validation_data=validation_batches,\n",
        "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "    validation_steps=totalVal // BATCH_SIZE)\n",
        "\n",
        "# reset the testing generator and evaluate the network after\n",
        "# fine-tuning just the network head\n",
        "print(\"[INFO] evaluating after fine-tuning network head...\")\n",
        "test_batches.reset()\n",
        "predIdxs = model.predict(x=test_batches, steps=(totalTest // BATCH_SIZE) + 1)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(test_batches.classes, predIdxs, target_names=test_batches.class_indices.keys()))\n",
        "plot_training(history, initial_epochs, WARMUP_PLOT_PATH)\n",
        "model.save(\"model\", save_format=\"h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKhFZTiaf9Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_4vsOxgf9XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGtqvNDMf9VM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}