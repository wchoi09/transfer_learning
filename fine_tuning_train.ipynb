{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fine_tuning_train.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyNpfH+tO8jDcKq3PPeMmRPr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"FGWVzanEeMw6","colab_type":"code","colab":{}},"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use(\"Agg\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFc3hk-0ecZQ","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Conv2D\n","from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD\n","from sklearn.metrics import classification_report\n","import conf\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import tensorflow as tf\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7zCGr9Fesjb","colab_type":"code","colab":{}},"source":["from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","sess_config = ConfigProto()\n","sess_config.gpu_options.per_process_gpu_memory_fraction = 0.8\n","sess_config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=sess_config)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwbIh6Kle98O","colab_type":"code","colab":{}},"source":["def plot_training(history, N, plotPath):\n","    # construct a plot that plots and saves the training history\n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n","    plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n","    plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n","    plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n","    plt.title(\"Training Loss and Accuracy\")\n","    plt.xlabel(\"Epoch #\")\n","    plt.ylabel(\"Loss/Accuracy\")\n","    plt.legend(loc=\"lower left\")\n","    plt.savefig(plotPath)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZw4TpLse9-b","colab_type":"code","colab":{}},"source":["# derive the paths to the training, validation, and testing\n","# directories\n","trainPath = os.path.sep.join([config2.BASE_PATH, config2.TRAIN])\n","valPath = os.path.sep.join([config2.BASE_PATH, config2.VAL])\n","testPath = os.path.sep.join([config2.BASE_PATH, config2.TEST])\n","\n","# determine the total number of image paths in training, validation, \n","# and testing directories\n","totalTrain = len(list(paths.list_images(trainPath)))\n","totalVal = len(list(paths.list_images(valPath)))\n","totalTest = len(list(paths.list_images(testPath)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cHxsZ4Y4e-BS","colab_type":"code","colab":{}},"source":["# initialize the training data augmentation object\n","train_Aug = ImageDataGenerator(\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    zoom_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\")\n","\n","# initialize the validation/testing data augmentation object (which\n","# we'll be adding mean subtraction to)\n","val_Aug = ImageDataGenerator()\n","\n","# define the ImageNet mean subtraction (in RGB order) and set the\n","# mean subtraction value for each of the data augmentation\n","# objects\n","mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n","train_Aug.mean = mean\n","val_Aug.mean = mean"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bSvyfV0gtva","colab_type":"code","colab":{}},"source":["# VALUE INIT\n","IMG_SIZE = 224\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","base_learning_rate = 1e-3\n","initial_epochs = 50\n","fine_tune_epochs = 10\n","#total_epochs = initial_epochs - fine_tune_epochs\n","total_epochs = fine_tune_epochs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKGkxktHe-Ei","colab_type":"code","colab":{}},"source":["# initialize the training generator\n","train_batches = train_Aug.flow_from_directory(\n","    trainPath,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    color_mode=\"rgb\",\n","    shuffle=True,\n","    batch_size=config2.BATCH_SIZE,\n","    class_mode=\"categorical\")\n","\n","# initialize the validation generator\n","validation_batches = val_Aug.flow_from_directory(\n","    valPath,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    color_mode=\"rgb\",\n","    shuffle=False,\n","    batch_size=config2.BATCH_SIZE,\n","    class_mode=\"categorical\")\n","\n","# initialize the testing generator\n","test_batches = val_Aug.flow_from_directory(\n","    testPath,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    color_mode=\"rgb\",\n","    shuffle=False,\n","    batch_size=config2.BATCH_SIZE,\n","    class_mode=\"categorical\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zniCppke-G9","colab_type":"code","colab":{}},"source":["# Create the base model from the pre-trained model \n","base_model = VGG16(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False)\n","#base_model = MobileNetV2(input_tensor=Input(shape=IMG_SHAPE), weights=\"imagenet\", include_top=False)\n","\n","# add a global spatial average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Flatten(name=\"flatten\")(x)\n","# let's add a fully-connected layer\n","x = Dense(512, activation=\"relu\")(x) # VGG16\n","#x = Dense(1280, activation=\"relu\")(x) # mobilenetv2\n","x = Dropout(0.5)(x)\n","# and a logistic layer -- let's say we have config2.CLASSES classes\n","predictions = Dense(len(config2.CLASSES), activation=\"softmax\")(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbClhdK4e-O5","colab_type":"code","colab":{}},"source":["# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional InceptionV3 layers\n","for layer in base_model.layers:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1L45m0We-M7","colab_type":"code","colab":{}},"source":["# compile the model (should be done *after* setting layers to non-trainable)\n","#model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","print(\"[INFO] compiling model...\")\n","opt = SGD(lr=base_learning_rate, momentum=0.9, decay=0.01)\n","#opt = SGD(lr=base_learning_rate, momentum=0.9, decay=base_learning_rate/initial_epochs)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","# train the head of the network for a few epochs (all other layers\n","# are frozen) -- this will allow the new FC layers to start to become\n","# initialized with actual \"learned\" values versus pure random\n","print(\"[INFO] training head...\")\n","history = model.fit(train_batches,\n","    epochs=initial_epochs,\n","    validation_data=validation_batches,\n","    steps_per_epoch=totalTrain // config2.BATCH_SIZE,\n","    validation_steps=totalVal // config2.BATCH_SIZE)\n","\n","# reset the testing generator and evaluate the network after\n","# fine-tuning just the network head\n","print(\"[INFO] evaluating after fine-tuning network head...\")\n","test_batches.reset()\n","predIdxs = model.predict(x=test_batches, steps=(totalTest // config2.BATCH_SIZE) + 1)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print(classification_report(test_batches.classes, predIdxs, target_names=test_batches.class_indices.keys()))\n","plot_training(history, initial_epochs, config2.WARMUP_PLOT_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSkPG2u-e-LW","colab_type":"code","colab":{}},"source":["# reset our data generators\n","train_batches.reset()\n","validation_batches.reset()\n","\n","base_model.trainable = True\n","\n","# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \" , len(base_model.layers))\n","\n","# Fine-tune from this layer onwards\n","fine_tune_at = 15 # VGG\n","#fine_tune_at = 100 # MobilenetV2\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable = False\n","\n","# loop over the layers in the model and show which ones are trainable\n","# or not\n","for layer in base_model.layers:\n","    print(\"{}: {}\".format(layer, layer.trainable))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8WRRuK2f9GV","colab_type":"code","colab":{}},"source":["# for the changes to the model to take affect we need to recompile\n","# the model, this time using SGD with a *very* small learning rate\n","print(\"[INFO] re-compiling model...\")\n","opt = SGD(lr=base_learning_rate/10, momentum=0.9, decay=0.001)\n","#opt = SGD(lr=base_learning_rate/10, momentum=0.9, decay=(base_learning_rate/10)/total_epochs)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","# train the model again, this time fine-tuning *both* the final set\n","# of CONV layers along with our set of FC layers\n","history = model.fit(train_batches,\n","    epochs=total_epochs,\n","    validation_data=validation_batches,\n","    steps_per_epoch=totalTrain // config2.BATCH_SIZE,\n","    validation_steps=totalVal // config2.BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AROJiqTlf9L9","colab_type":"code","colab":{}},"source":["# reset the testing generator and then use our trained model to\n","# make predictions on the data\n","print(\"[INFO] evaluating after fine-tuning network...\")\n","test_batches.reset()\n","predIdxs = model.predict(x=test_batches, steps=(totalTest // config2.BATCH_SIZE) + 1)\n","predIdxs = np.argmax(predIdxs, axis=1)\n","print(classification_report(test_batches.classes, predIdxs, target_names=test_batches.class_indices.keys()))\n","plot_training(history, total_epochs, config2.UNFROZEN_PLOT_PATH)\n","\n","# serialize the model to disk\n","print(\"[INFO] serializing network...\")\n","model.save(config2.MODEL_PATH, save_format=\"h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKhFZTiaf9Zw","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_4vsOxgf9XX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGtqvNDMf9VM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}